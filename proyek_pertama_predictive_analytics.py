# -*- coding: utf-8 -*-
"""Proyek Pertama : Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NYlscH2Yh2PqIqOn8HN-Xkny8hABzPvo

# **Clustering Pokemon Dataset - Mizwar**

## **Domain Proyek**

* Pada proyek kali ini, saya akan melakukan metode Unsupervised Learning dengan algoritma Clustering pada data Pokemon milik akun https://gist.github.com/armgilles/194bcff35001e7eb53a2a8b441e8b2c6#file-pokemon-csv . Dataset pokemon, saya download kemudian mengupload kembali ke akun github saya sendiri untuk selanjutnya load dataset melalui link github tersebut.

* Game Pokemon adalah salah satu game populer di dunia saat ini, salah satu game populer adalah 'Pokemon Go'. Ini merupakan game berbasis augmented-reality yang dikembangkan oleh Pokemon Company bekerja sama dengan Nintendo dan Niantic *.

* Masalah yang ingin saya teliti adalah terkait 'Hero' pada Pokemon, saya ingin melihat cluster/pengelompokan 'Attack' dan 'Defence' pada 'Hero' dataset Pokemon.

*Artikel ini telah tayang di Kompas.com dengan judul "Apa Itu Pokemon Go?", Klik untuk baca: https://tekno.kompas.com/read/2016/07/09/13200047/apa.itu.pokemon.go.?page=all.
Penulis : Deliusno

## **Data Loading**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as 
from pandas import DataFrame
from pandas.plotting import scatter_matrix
from matplotlib import pyplot
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# load the dataset
url = 'https://raw.githubusercontent.com/Mizwar90/Pokemon-Predictive-Analytics/main/pokemon.csv'
data = pd.read_csv(url)
data

"""## **Exploratory Data Analysis - Deskripsi Variabel**"""

data.info()

"""Dari output terlihat bahwa:

* Terdapat 3 kolom dengan tipe object, yaitu: Name, Type 1 dan Type 2. Kolom ini merupakan categorical features (fitur non-numerik).

* Terdapat 1 kolom dengan tipe data bool yaitu: Legendary. Ini merupakan fitur untuk menentukan benar dan salah dalam data.

* Terdapat 9 kolom numerik dengan tipe data int64, kolom Attack dan Defense adalah target fitur kita.

### Membuat salinan dataframe dengan dua kolom yaitu attack dan defense
"""

df = data[['Attack', 'Defense']]
df

"""## **Melakukan transformasi pada data**

### Cek missing value
"""

df.isnull().sum()

"""### Cek nilai pencilan/outlier

Pencilan/Outlier adalah data atau pengamatan yang tampak menyimpang secara nyata dari pengamatan lain dalam sampel. Biasanya pencilan terletak jauh atau sangat berbeda dari nilai-nilai lain dalam sampel acak dari suatu populasi.
"""

fig = plt.figure(figsize=(19, 9))

plt.subplot(1, 2, 1)
sns.boxplot(x = 'Attack', data = df)

plt.subplot(1, 2, 2)
sns.boxplot(x = 'Defense', data = df)

plt.show()

"""## **Menangani Missing Value**

### Membuat fungsi untuk menangani outlier dengan teknik IQR method

IQR adalah singkatan dari Inter Quartile Range. Untuk memahami apa itu IQR, mari kita ingat lagi konsep kuartil. Kuartil dari suatu populasi adalah tiga nilai yang membagi distribusi data menjadi empat sebaran. Seperempat dari data berada di bawah kuartil pertama (Q1), setengah dari data berada di bawah kuartil kedua (Q2), dan tiga perempat dari data berada di kuartil ketiga (Q3). Dengan demikian interquartile range atau IQR = Q3 - Q1.
"""

def get_lower_upper(x):
  Q1 = np.percentile(x, 25)
  Q3 = np.percentile(x, 75)
  IQR = Q3 - Q1
  lower = Q1 - (IQR*1.5)
  upper = Q3 + (IQR*1.5)

  return lower, upper

def get_outlier(x):
  lower, upper = get_lower_upper(x)

  return x[(x > lower) & (x < upper)]

df['Attack'] = get_outlier(df['Attack'])

df['Defense'] = get_outlier(df['Defense'])

"""### Menangani Missing Value dengan fungsi dropna"""

df = df.dropna()
df

"""### Cek nilai pencilan/outlier kembali"""

fig = plt.figure(figsize=(19, 9))

plt.subplot(1, 2, 1)
sns.boxplot(x = 'Attack', data = df)

plt.subplot(1, 2, 2)
sns.boxplot(x = 'Defense', data = df)

plt.show()

"""## **Data scaling/normalisasi data**

"""

scal = df[["Attack", "Defense"]]
scal

"""### Cek data sebelum scaling dengan fungsi describe dan histogram"""

print(scal.describe())
scal.hist()
pyplot.show()

"""### Data sesudah scaling menggunakan fungsi StandarScaler"""

# perform a robust scaler transform of the dataset
trans = StandardScaler()
scal2 = trans.fit_transform(scal)
# convert the array back to a dataframe
dataset = DataFrame(scal2)
# summarize
print(dataset.describe())
# histograms of the variables
dataset.hist()
pyplot.show()
dataset

"""##**Clustering menggunakan K-Means**

K-Means clustering adalah algoritma unsupervised learning yang dipakai untuk mengelompokkan dataset yang belum dilabel ke dalam kluster yang berbeda. Simbol K pada K-means clustering menandakan jumlah kluster yang digunakan. 

Adapun kelebihan dari algoritma K-Means adalah sebagai berikut:
* Relatif sederhana dan mudah untuk diterapkan.
* Dapat diskalakan untuk dataset dalam jumlah besar.
* Mudah beradaptasi dengan contoh baru.
* Umum diimplementasikan ke cluster dengan bentuk dan ukuran yang berbeda, seperti cluster elips.

Adapun kelemahan atau kekurangan dari algoritma K-means di antaranya:
* Perlu menentukan nilai k secara manual
* Sangat bergantung pada inisialisasi awal. Jika nilai random untuk inisialisasi kurang baik, maka pengelompokkan yang dihasilkan pun menjadi kurang optimal.
* Dapat terjadi curse of dimensionality. Masalah ini timbul jika dataset memiliki dimensi yang sangat tinggi. Cara kerja algoritma ini adalah mencari jarak terdekat antara k buah titik dengan titik lainnya. Mencari jarak antar titik pada 2 dimensi, kemungkinan masih mudah dilakukan. Namun apabila dimensi bertambah menjadi 20 tentunya hal ini akan menjadi sulit.
* K-means mengalami kesulitan mengelompokkan data di mana cluster memiliki ukuran dan kepadatan yang bervariasi.

Berikut adalah beberapa penerapan dari K-means clustering

* Segmentasi pasar
* Pengelompokan dokumen
* Segmentasi gambar
* Kompresi gambar
* Kuantisasi vektor
* Analisis klaster
* Identifikasi daerah rawan kejahatan
* Deteksi penipuan asuransi
* Analisis data angkutan umum
* Pengelompokan aset IT
* Segmentasi pelanggan
* Mengidentifikasi data kanker

Referensi: https://www.trivusi.web.id/2022/06/algoritma-kmeans-clustering.html#:~:text=Pengertian%20K%2Dmeans%20Clustering,-K%2DMeans%20clustering&text=Simbol%20K%20pada%20K%2Dmeans,dikumpulkan%20bersama%20karena%20kesamaan%20tertentu.

### Jumlah cluster 2
"""

kmeans = KMeans(n_clusters=2, random_state=42).fit(scal2)
labels = kmeans.labels_

new_scal2 = pd.DataFrame(data = scal2, columns = ['Attack','Defense'])
new_scal2['label_kmeans'] = labels


fig, ax = plt.subplots(figsize=(14,7))
plt.scatter(new_scal2["Attack"][new_scal2["label_kmeans"] == 0], new_scal2["Defense"][new_scal2["label_kmeans"] == 0], 
            color = "blue", s=100, edgecolor='green',linestyle='--')
plt.scatter(new_scal2["Attack"][new_scal2["label_kmeans"] == 1], new_scal2["Defense"][new_scal2["label_kmeans"] == 1], 
            color = "red", s=100, edgecolor='green',linestyle='--')
#plt.scatter(new_scal2["Attack"][new_scal2["label_kmeans"] == 2], new_scal2["Defense"][new_scal2["label_kmeans"] == 2], 
#            color = "green", s=100, edgecolor='green',linestyle='--')


centers = kmeans.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='black', s=300);
ax.set_xlabel('Attack')
ax.set_ylabel('Defense')
plt.show()

"""### Membuat fungsi Metode Elbow

Metode Elbow merupakan suatu metode yang digunakan untuk menghasilkan informasi dalam menentukan jumlah cluster yang akan membentuk siku pada suatu titik.
"""

wcss = []
for i in range(1, 11):
  kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
  kmeans.fit(new_scal2)
  wcss.append(kmeans.inertia_)

fig, ax = plt.subplots(figsize=(12,7))  
plt.plot(range(1, 11), wcss)
plt.title('Elbow Method')
plt.xlabel('n_cluster')
plt.ylabel('wcss')
plt.show()

"""### Jumlah cluster 3"""

kmeans2 = KMeans(n_clusters=3, random_state=42).fit(scal2)
labels2 = kmeans2.labels_

new_scal3 = pd.DataFrame(data = scal2, columns = ['Attack','Defense'])
new_scal3['label_kmeans2'] = labels2


fig, ax = plt.subplots(figsize=(14,7))
plt.scatter(new_scal3["Attack"][new_scal3["label_kmeans2"] == 0], new_scal3["Defense"][new_scal3["label_kmeans2"] == 0], 
            color = "green", s=100, edgecolor='green',linestyle='--', label = 0)
plt.scatter(new_scal3["Attack"][new_scal3["label_kmeans2"] == 2], new_scal3["Defense"][new_scal3["label_kmeans2"] == 2], 
            color = "red", s=100, edgecolor='green',linestyle='--', label = 1)
plt.scatter(new_scal3["Attack"][new_scal3["label_kmeans2"] == 1], new_scal3["Defense"][new_scal3["label_kmeans2"] == 1], 
            color = "blue", s=100, edgecolor='green',linestyle='--', label = 2)


centers = kmeans2.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='black', s=300);
ax.set_xlabel('Attack')
ax.set_ylabel('Defense')

plt.legend()
plt.show()

"""### Jumlah cluster 4"""

kmeans3 = KMeans(n_clusters=4, random_state=42).fit(scal2)
labels3 = kmeans3.labels_

new_scal4 = pd.DataFrame(data = scal2, columns = ['Attack','Defense'])
new_scal4['label_kmeans3'] = labels3


fig, ax = plt.subplots(figsize=(14,7))
plt.scatter(new_scal4["Attack"][new_scal4["label_kmeans3"] == 0], new_scal4["Defense"][new_scal4["label_kmeans3"] == 0], 
            color = "green", s=100, edgecolor='green',linestyle='--', label = 0)
plt.scatter(new_scal4["Attack"][new_scal4["label_kmeans3"] == 2], new_scal4["Defense"][new_scal4["label_kmeans3"] == 2], 
            color = "red", s=100, edgecolor='green',linestyle='--', label = 1)
plt.scatter(new_scal4["Attack"][new_scal4["label_kmeans3"] == 1], new_scal4["Defense"][new_scal4["label_kmeans3"] == 1], 
            color = "blue", s=100, edgecolor='green',linestyle='--', label = 2)
plt.scatter(new_scal4["Attack"][new_scal4["label_kmeans3"] == 3], new_scal4["Defense"][new_scal4["label_kmeans3"] == 3], 
            color = "y", s=100, edgecolor='green',linestyle='--', label = 3)


centers = kmeans3.cluster_centers_
plt.scatter(centers[:, 0], centers[:, 1], c='black', s=300);
ax.set_xlabel('Attack')
ax.set_ylabel('Defense')

plt.legend()
plt.show()

"""##**Silhouette Score**

Skor Silhouette dalam algoritma pengelompokan K-Means adalah antara -1 dan 1. Skor ini menunjukkan seberapa baik titik data telah dikelompokkan, dan skor di atas 0 dianggap baik, sedangkan poin negatif berarti algoritme K-means Anda telah menempatkannya di titik data cluster yang salah)
"""

from sklearn.metrics import silhouette_score

print(silhouette_score(new_scal2, labels = labels))
print(silhouette_score(new_scal3, labels = labels2))
print(silhouette_score(new_scal4, labels = labels3))

"""Dari hasil klustering diatas, kita dapat mengambil kesimpulan sebagai berikut:

* Berdasarkan **Elbow Method** kita dapat mengambil **jumlah cluster optimal sebesar 2 cluster** karna lebih mencerminkan segmentasi kelompok data defence dan attack secara keseluruhan jika kita mengeneralisasi data.

* Berdasarkan metrik **silhouette score**, yang mendekati nilai 1 adalah cluster yang berjumlah 4 yang menggunakan algoritma K-Means. 

Kesimpulan: Kedua metode diatas bisa digunakan salah satu atau keduanya tergantung permasalahan apa yang ingin dipecahkan. Disini saya ingin menjabarkan hasil yang didapatkan clustering (pengelompokan) algoritma K-Means yang memiliki jumlah cluster 4. Sekilas dapat kita lihat visualisasi, jika semakin kecil attack maka semakin kecil pula defence dan semakin besar attack maka semakin besar pula defence. Hanya sebagian kecil cluster 3 (color = yellow) defence tinggi namun attack berada di tengah, begitu pula cluster 2 (color = blue) attack tinggi namun defence berada di tengah. **Secara keseluruhan, dapat disimpulkan 'Attack' dan 'Defence' pada 'Hero' dataset pokemon berbanding lurus jika dilihat dari pengelompokan yang ada**.
"""